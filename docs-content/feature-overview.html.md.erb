---
title: Feature Overview of Crunchy PostgreSQL for PCF
owner: Crunchy Data
---

This topic describes the features of <%= vars.service_name_long -%>.

##<a id ="plans"></a> Plans

The <%= vars.service_name_long -%> offers several out-of-the-box (configurable) plans.
When deploying the service, operators have the opportunity to tune these plans for the needs of the environment.

###<a id='plansize'></a> Plan Sizes

The plans that are included are as follows:

<% vars.service_plans.each do |service| -%>
- <%= service %>
<% end -%>

###<a id='suggested_plan'></a> Suggested Plan Configuration

The following table suggests recommendations for configuring plans.
These recommendations do not accommodate every app.
However, they provide a starting point for operators to configure their tile.

| Plan   | vCPU | Memory | Disk  |
|--------|------|--------|-------|
| Small  | 4    | 32GB   | 64GB  |
| Medium | 8    | 64GB   | 128GB |
| Large  | 16   | 128GB  | 256GB |
| XLarge | 32   | 256GB  | 512GB |

<p class="note"><strong>Note</strong>: Part of maintaining high availability is having room to grow the database.
   Therefore, operators and developers should consider the rate at which they expect to grow and select an appropriate plan.</p>

###<a id='cluster_config'></a> Default Cluster Configurations

The following table provides information about the out-of-the-box cluster configurations:

| Plan   | Replica | Connections |
|--------|---------|-------------|
| Small  | 1       | 100         |
| Medium | 2       | 100         |
| Large  | 2       | 200         |
| XLarge | 2       | 500         |

The current limitations for these cluster configurations are as follows:

- The number of replicas and connections are not yet configurable.
- All replicas use `async` replication. `sync` replication is not yet configurable.

##<a id="backups"></a> Automated Backups
<%= partial('backup_information') -%>

##<a id="load-balance"></a> Load Balancing

Crunchy PostgreSQL for PCF uses `HAProxy` as a single point of entry to the database cluster.
App developers must switch ports depending on the type of cluster they want to interact with.

###<a id='ports'></a> Selectively Accessing Clusters

By using port switching, apps have the ability to manage the types of database interactions their app needs.
When used correctly, this strategy allows apps to be more performant.

To query a `primary` cluster, apps must use the `5432` port on the load balancer.
This ensures that writes or reads are redirected to the primary cluster.

To query a `replica`, apps must use the `5433` port on the load balancer.
This ensures that reads are redirected to the replica cluster.

##<a id="ha-model"></a> HA Model

Crunchy PostgreSQL for PCF provisions a cluster of PostgreSQL servers and self-configures their roles (primary and many replicas).
This allows the servers to change their roles when failures are detected.

Crunchy PostgreSQL for PCF configuration files are managed by `consul-template`.
Each of these templates watch different parts of the stack.
When changes are detected, configuration files automatically are rendered with the latest state.
This allows the system to be dynamic and change depending on state of services.

For example, the PostgreSQL load balancer automatically detects when replicas are added or removed,
and reconfigures its pool to reflect the current state.

###<a id='autofailover'></a> Automatic Failover

Crunchy Cluster Manager runs on each of the Consul Servers within the Crunchy PostgreSQL for PCF.
The job of CCM is to detect failures of the PostgreSQL servers and to determine who is the best candidate to replace a failed primary.
CCM measures replication lag to determine the best candidate to elect for the primary role.

Once a new primary role is elected, CCM updates the Consul Service Catalog to reflect the new state.
The newly elected primary reconfigures itself (trigger a failover) and all other services detect the new primary.

Failed former primaries are put into a fenced state.
This tells the rest of the stack to no longer communicate with the failed service.
An hourly `cron` job attempts to repair fenced servers and add them to the replica pool.

![Model](http://i.imgur.com/sxamhbn.png)

##<a id="tools"></a> Tools

Crunchy PostgreSQL for PCF offers two tools to help developers manage their system:

* cf-pgadmin4
* cf-pgloader
